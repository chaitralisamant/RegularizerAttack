{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Attack Evaluation\n",
        "\n",
        "Testing the attack against multiple different popular attacks (FGSM, PGD). Cannot get C&W to work as of right now."
      ],
      "metadata": {
        "id": "7g0lShDYJx5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "id": "ddM6kS8f6NsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "with open('model (1).pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "Rb2YHnZQ6ZAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import random\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "IiD18ogn_vUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess with only 200 images\n",
        "def preprocess_inputs(filepath):\n",
        "\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "    val_dataset = datasets.ImageFolder(root=filepath, transform=preprocess)\n",
        "    indices = random.sample(range(len(val_dataset)), 200)\n",
        "    reduced_dataset = Subset(val_dataset, indices)\n",
        "\n",
        "    imagenette_val = DataLoader(reduced_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    return imagenette_val"
      ],
      "metadata": {
        "id": "HwFNk1ch6luh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, attack=None, device='cuda'):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad() if attack is None else torch.enable_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            if attack is not None:\n",
        "                images = attack(model, images, labels)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    avg_loss = total_loss / total\n",
        "    return accuracy, avg_loss"
      ],
      "metadata": {
        "id": "QMj3d91M6rNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the attacks\n",
        "from torchattacks import CW"
      ],
      "metadata": {
        "id": "m78x77X27K7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom attack\n",
        "def adversarial_attack(model, clean_img, targets, lambda_reg=0.1, epsilon=0.03, iterations=10):\n",
        "    delta = torch.zeros_like(clean_img, requires_grad=True)\n",
        "\n",
        "    optimizer = torch.optim.Adam([delta], lr=0.01)\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        preds = model(clean_img + delta)\n",
        "        loss = F.cross_entropy(preds, targets)\n",
        "\n",
        "        # Regularization-aware perturbation loss (modify R(delta) as needed)\n",
        "        reg_loss = lambda_reg * torch.norm(delta, p=2)\n",
        "\n",
        "        total_loss = loss - reg_loss  # Counteract the regularizer\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Keep perturbations within a valid range\n",
        "        delta.data = torch.clamp(delta, -epsilon, epsilon)\n",
        "        delta.data = torch.clamp(clean_img + delta, 0, 1) - clean_img\n",
        "\n",
        "    return clean_img + delta\n",
        "\n",
        "\n",
        "# Fast Gradient Sign Method\n",
        "def fgsm_attack(model, clean_img, targets, epsilon=0.03):\n",
        "    clean_img = clean_img.clone().detach()\n",
        "    clean_img.requires_grad = True\n",
        "    output = model(clean_img)\n",
        "    loss = F.cross_entropy(output, targets)\n",
        "    #clean_img.requires_grad = True\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    perturbed_img = clean_img + epsilon * clean_img.grad.sign()\n",
        "    perturbed_img = torch.clamp(perturbed_img, 0, 1)\n",
        "\n",
        "    return perturbed_img\n",
        "\n",
        "\n",
        "#Projected Gradient Descent\n",
        "def pgd_attack(model, clean_img, targets, alpha=0.1, epsilon=0.03, iterations=10):\n",
        "\n",
        "  clean_copy = clean_img.clone()\n",
        "\n",
        "  for i in range(clean_img.size(0)):\n",
        "      x_adv = clean_img.clone().detach()\n",
        "      x_adv.requires_grad = True\n",
        "\n",
        "      for _ in range(iterations):\n",
        "          outputs = model(x_adv)\n",
        "          loss = F.cross_entropy(outputs, targets)\n",
        "          model.zero_grad()\n",
        "          loss.backward()\n",
        "          x_adv = x_adv + alpha * x_adv.grad.sign()\n",
        "          x_adv = torch.min(torch.max(x_adv, clean_copy - epsilon), clean_copy + epsilon)\n",
        "          x_adv = torch.clamp(x_adv, 0, 1).detach().requires_grad_()\n",
        "\n",
        "  return x_adv\n",
        "\n",
        "\n",
        "\n",
        "#Carlini and Wagner\n",
        "# def cw_attack(model, clean_img, targets, c=1.0, kappa=0, steps=1000, lr=0.01, num_samples=100):\n",
        "#     atk = CW(model, c=c, kappa=kappa, steps=steps, lr=lr)\n",
        "#     atk.set_return_type('float')  # returns tensor\n",
        "\n",
        "#     perturbed = atk(clean_img, targets)\n",
        "\n",
        "#     return perturbed\n"
      ],
      "metadata": {
        "id": "yaMmsUJ57Bgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load about 200 images to start\n",
        "val_data_path = '/content/drive/MyDrive/imagenette2/val'\n",
        "imagenette_val = preprocess_inputs(val_data_path)"
      ],
      "metadata": {
        "id": "sPeZTisq7KfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagenette_val)"
      ],
      "metadata": {
        "id": "lW7u-iJmA5vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating on all attacks\n",
        "\n",
        "print(\"Evaluating on clean data...\")\n",
        "clean_acc, clean_loss = evaluate(model, imagenette_val, attack=None)\n",
        "print(f\"Clean Accuracy: {clean_acc:.4f} | Loss: {clean_loss:.4f}\")\n",
        "\n",
        "print(\"Evaluating on adversarial (custom attack) data...\")\n",
        "adv_acc, adv_loss = evaluate(model, imagenette_val, attack=adversarial_attack)\n",
        "print(f\"Adversarial Accuracy: {adv_acc:.4f} | Loss: {adv_loss:.4f}\")\n",
        "\n",
        "# print(\"Evaluating on adversarial (C&W) data...\")\n",
        "# adv_acc, adv_loss = evaluate(model, imagenette_val, attack=cw_attack)\n",
        "# print(f\"Adversarial Accuracy: {adv_acc:.4f} | Loss: {adv_loss:.4f}\")"
      ],
      "metadata": {
        "id": "eQL8w-F-635O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating on adversarial (FGSM) data...\")\n",
        "adv_acc, adv_loss = evaluate(model, imagenette_val, attack=fgsm_attack)\n",
        "print(f\"Adversarial Accuracy: {adv_acc:.4f} | Loss: {adv_loss:.4f}\")\n",
        "\n",
        "print(\"Evaluating on adversarial (PGD) data...\")\n",
        "adv_acc, adv_loss = evaluate(model, imagenette_val, attack=pgd_attack)\n",
        "print(f\"Adversarial Accuracy: {adv_acc:.4f} | Loss: {adv_loss:.4f}\")"
      ],
      "metadata": {
        "id": "21T9wStnDfe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tuning hyperparameters"
      ],
      "metadata": {
        "id": "Lp0cRJep7Ayw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_img, targets = next(iter(imagenette_val))\n",
        "\n",
        "clean_img = clean_img.to('cuda')\n",
        "targets = targets.to('cuda')\n",
        "\n",
        "adv_image = adversarial_attack(model, clean_img, targets, lambda_reg=0.1, epsilon=0.03, iterations=10)\n",
        "\n",
        "save_image(adv_image[0], \"adv_01_003_10.png\")"
      ],
      "metadata": {
        "id": "YtnPLFdPBqJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_image = adversarial_attack(model, clean_img, targets, lambda_reg=0.05, epsilon=0.01, iterations=10)\n",
        "\n",
        "save_image(adv_image[0], \"adv_005_001_10.png\")"
      ],
      "metadata": {
        "id": "NTvTkoZeIqSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_image = adversarial_attack(model, clean_img, targets, lambda_reg=0.2, epsilon=0.06, iterations=10)\n",
        "\n",
        "save_image(adv_image[0], \"adv_02_006_10.png\")"
      ],
      "metadata": {
        "id": "eYfZa0IlIydV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_image = adversarial_attack(model, clean_img, targets, lambda_reg=0.05, epsilon=0.01, iterations=5)\n",
        "\n",
        "save_image(adv_image[0], \"adv_05_001_5.png\")"
      ],
      "metadata": {
        "id": "2eGt3fKhI6d7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}