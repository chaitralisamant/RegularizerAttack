{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Main Code\n",
        "\n",
        "This Notebook is where we develop all initial code for this experiment, and produce initial results."
      ],
      "metadata": {
        "id": "hRpzlJLxJBJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing and Definitions\n",
        "\n",
        "Preprocess data and define attack + regularizer"
      ],
      "metadata": {
        "id": "6zE593wRHw7q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aprzD49t40ST"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Subset"
      ],
      "metadata": {
        "id": "Xfp2Zillecxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_inputs(filepath):\n",
        "\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "    val_dataset = datasets.ImageFolder(root=filepath, transform=preprocess)\n",
        "    every_other_index = list(range(0, len(val_dataset), 2))\n",
        "    reduced_dataset = Subset(val_dataset, every_other_index)\n",
        "\n",
        "    imagenette_val = DataLoader(reduced_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    # #input_batch = []\n",
        "    # input_tensors = []\n",
        "\n",
        "    # for image in images:\n",
        "    #     input_img = Image.open(image)\n",
        "    #     input_tensor = preprocess(input_img)\n",
        "    #     input_tensors.append(input_tensor)\n",
        "\n",
        "    # input_batch = torch.stack(input_tensors)\n",
        "\n",
        "    return imagenette_val #returns the dataloader\n",
        "\n",
        "#variance based adam regularizer\n",
        "#recomputes loss\n",
        "def variance_adam_regularizer(model, inputs, targets, loss_fn, lambda_reg=0.1):\n",
        "    \"\"\"\n",
        "    Computes loss + variance-based regularization term.\n",
        "\n",
        "    Args:\n",
        "        model: pretrained resnet\n",
        "        inputs: input batch\n",
        "        targets: target labels\n",
        "        loss_fn: (nn.CrossEntropyLoss)\n",
        "        lambda_reg: strength of reg\n",
        "\n",
        "    Returns:\n",
        "        total loss (mean + lambda * variance)\n",
        "    \"\"\"\n",
        "    outputs = model(inputs)\n",
        "    per_sample_loss = loss_fn(outputs, targets)  # shape: [batch_size]\n",
        "\n",
        "    # Mean and variance of the per-sample losses\n",
        "    mean_loss = per_sample_loss.mean()\n",
        "    variance = per_sample_loss.var(unbiased=False)\n",
        "\n",
        "    # Total loss with variance regularization\n",
        "    total_loss = mean_loss + lambda_reg * variance\n",
        "    return total_loss\n",
        "\n",
        "# basic gradient norm regularizer\n",
        "# recomputes loss\n",
        "def gradient_norm_regularizer(model, inputs, targets, loss_fn, lambda_reg=0.1):\n",
        "    inputs.requires_grad = True  # Track gradients\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    grads = torch.autograd.grad(loss, inputs, create_graph=True)[0]\n",
        "    grad_norm = torch.norm(grads, p=2)  # Compute L2 norm of gradients\n",
        "\n",
        "    total_loss = loss + lambda_reg * grad_norm  # Add regularization\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "# Step 3: defining optimizer-based attack\n",
        "def adversarial_attack(model, clean_img, targets, lambda_reg=0.1, epsilon=0.03, iterations=10):\n",
        "    delta = torch.zeros_like(clean_img, requires_grad=True)\n",
        "\n",
        "    optimizer = torch.optim.Adam([delta], lr=0.01)\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        preds = model(clean_img + delta)\n",
        "        loss = F.cross_entropy(preds, targets)\n",
        "\n",
        "        # Regularization-aware perturbation loss\n",
        "        reg_loss = lambda_reg * torch.norm(delta, p=2)\n",
        "\n",
        "        total_loss = loss - reg_loss  # Counteract the regularizer\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Keep perturbations within a valid range\n",
        "        delta.data = torch.clamp(delta, -epsilon, epsilon)\n",
        "        delta.data = torch.clamp(clean_img + delta, 0, 1) - clean_img\n",
        "\n",
        "    return clean_img + delta"
      ],
      "metadata": {
        "id": "LDaHIJly47zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model"
      ],
      "metadata": {
        "id": "VgrRUVebHqqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "id": "834fRB8O4_2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_data_path = '/content/drive/MyDrive/imagenette2/train'\n",
        "val_data_path = '/content/drive/MyDrive/imagenette2/val'\n",
        "# for cls in os.listdir(train_data_path):\n",
        "#     print(cls, \"->\", len(os.listdir(os.path.join(train_data_path, cls))), \"files\")"
      ],
      "metadata": {
        "id": "syJmixmIsrI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagenette_train = preprocess_inputs(train_data_path)\n",
        "imagenette_val = preprocess_inputs(val_data_path)"
      ],
      "metadata": {
        "id": "sLqwc8RY_-29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting pretrained resnet50 imagenet\n",
        "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "\n",
        "model = model.to('cuda')\n",
        "\n",
        "# output_root = 'attack_imagenette'\n",
        "\n",
        "# for class_name in labels:\n",
        "#     os.makedirs(output_root, exist_ok=True)\n",
        "\n",
        "#imagenette_train = preprocess_inputs('/content/imagenette2/imagenette2/train')\n",
        "\n",
        "\n",
        "# Set hyperparameters\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model...\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in imagenette_train:\n",
        "        # Move input and label tensors to the device\n",
        "        inputs = inputs.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        #breakpoint()\n",
        "\n",
        "        # Zero out the optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        # loss = criterion(outputs, labels)\n",
        "        loss = variance_adam_regularizer(model, inputs, labels, criterion) #regularizer part\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #print(f'Loss: {loss.item():.4f}')\n",
        "        #print(f'Output: {outputs}')\n",
        "\n",
        "    # Print the loss for every epoch\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "print(f'Finished Training, Loss: {loss.item():.4f}')\n",
        "\n",
        "with open('model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "idx = 0"
      ],
      "metadata": {
        "id": "iKgq38fL5EPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing and Evaluation\n",
        "\n",
        "Session 2: saving dataset, testing, and random visualizations"
      ],
      "metadata": {
        "id": "CF57ZYWcHhr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('model.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "\n",
        "model.eval()  # Important if you're doing inference"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ruoNhm8P-XAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input = 224 x 224 x 3\n",
        "class_names = ['tench', 'English springer', 'cassette player',\n",
        "          'chain saw', 'church', 'French horn',\n",
        "          'garbage truck', 'gas pump', 'golf ball', 'parachute']"
      ],
      "metadata": {
        "id": "LBLh51h5-9-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_root = 'attack_imagenette'\n",
        "\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(output_root, class_name)\n",
        "    os.makedirs(class_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "9RVZL150-yFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save ALL attacked images to attack_imagenette\n",
        "\n",
        "idx = 0\n",
        "\n",
        "for inputs, labels in imagenette_val:\n",
        "    model = model.to('cuda')\n",
        "    inputs = inputs.to('cuda')\n",
        "    labels = labels.to('cuda')\n",
        "\n",
        "    attacked_batch = adversarial_attack(model, inputs, labels)\n",
        "\n",
        "    for i in range(attacked_batch.size(0)):\n",
        "      true_label = labels[i].item()\n",
        "      img = attacked_batch[i]\n",
        "      # Get the folder corresponding to the true label\n",
        "      class_name = class_names[true_label]\n",
        "      class_folder = os.path.join(output_root, class_name)\n",
        "\n",
        "      output_path = os.path.join(class_folder, f\"{idx:05d}.png\")\n",
        "      save_image(img.unsqueeze(0), output_path)\n",
        "\n",
        "      idx = idx + 1"
      ],
      "metadata": {
        "id": "ZECn8U4PzEfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "zB99TuZHengy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image\n",
        "img = Image.open('/content/attack_imagenette/chain saw/00047.png')\n",
        "\n",
        "# Define transformations: Resize and convert to tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to fit model input size (e.g., 224x224 for ResNet)\n",
        "    transforms.ToTensor(),          # Convert image to tensor\n",
        "])\n",
        "\n",
        "# Apply transformations\n",
        "img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Move tensor to the same device as model (GPU/CPU)\n",
        "img_tensor = img_tensor.to('cuda')\n",
        "\n",
        "with torch.no_grad():  # No need to track gradients during inference\n",
        "    output = model(img_tensor)\n",
        "\n",
        "# Get predicted label (index of max output)\n",
        "_, predicted_label = torch.max(output, 1)\n",
        "\n",
        "# Print predicted label\n",
        "class_label = class_names[predicted_label.item()]\n",
        "print(f\"Predicted label: {class_label}\")\n"
      ],
      "metadata": {
        "id": "HQ9hK2vdBn8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, attack=None, device='cpu'):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad() if attack is None else torch.enable_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            if attack is not None:\n",
        "                images = attack(model, images, labels)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    avg_loss = total_loss / total\n",
        "    return accuracy, avg_loss"
      ],
      "metadata": {
        "id": "t5Gjp6T5HeAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Various evaluations on model, attack, and regularizer"
      ],
      "metadata": {
        "id": "LjZScoUdHa_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate on clean AND attacked data\n",
        "# imagenette_clean = preprocess_inputs()\n",
        "print(\"Evaluating on clean data...\")\n",
        "clean_acc, clean_loss = evaluate(model, imagenette_val, attack=None)\n",
        "print(f\"Clean Accuracy: {clean_acc:.4f} | Loss: {clean_loss:.4f}\")\n",
        "\n",
        "#TODO: make adv attack data loader\n",
        "# attacked_val = preprocess_inputs('/content/attack_imagenette')\n",
        "\n",
        "print(\"Evaluating on adversarial (custom attack) data...\")\n",
        "adv_acc, adv_loss = evaluate(model, imagenette_val, attack=adversarial_attack)\n",
        "print(f\"Adversarial Accuracy: {adv_acc:.4f} | Loss: {adv_loss:.4f}\")"
      ],
      "metadata": {
        "id": "9x3S7otq55jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unregular_model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "unregular_model = unregular_model.to('cuda')\n",
        "print(\"Evaluating unregularized model on clean data...\")\n",
        "clean_acc, clean_loss = evaluate(unregular_model, imagenette_val, attack=None, device='cuda')\n",
        "print(f\"Clean Accuracy: {clean_acc:.4f} | Loss: {clean_loss:.4f}\")\n",
        "\n",
        "#TODO: make adv attack data loader\n",
        "# attacked_val = preprocess_inputs('/content/attack_imagenette')"
      ],
      "metadata": {
        "id": "dQh0GcMkN_1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating on unregularized model on adversarial (custom attack) data...\")\n",
        "unregular_model = unregular_model.to('cuda')\n",
        "adv_acc, adv_loss = evaluate(unregular_model, imagenette_val, attack=adversarial_attack, device='cuda')\n",
        "print(f\"Adversarial Accuracy: {adv_acc:.4f} | Loss: {adv_loss:.4f}\")"
      ],
      "metadata": {
        "id": "KUMdm17M380w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results and visualizations\n",
        "\n",
        "Plotting preliminary results"
      ],
      "metadata": {
        "id": "dc6YJg0WHUu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "epochs = list(range(1, 11))\n",
        "losses = [0.3337, 0.1190, 0.1235, 0.0661, 0.3400,\n",
        "          0.0031, 0.0952, 0.1418, 0.0176, 0.2048]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epochs, losses, marker='o', linestyle='-', color='blue')\n",
        "\n",
        "# Labels and title\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(top=1)\n",
        "plt.grid(True)\n",
        "plt.xticks(epochs)\n",
        "\n",
        "# Show\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vq9qQHhel4UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "labels = ['Clean', 'Adversarial']\n",
        "accuracy = [0.9609, 0.9050]\n",
        "loss = [0.1608, 0.3678]\n",
        "\n",
        "x = np.arange(len(labels))  # label locations\n",
        "width = 0.35  # bar width\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "bar1 = ax.bar(x - width/2, accuracy, width, label='Accuracy', color='green')\n",
        "bar2 = ax.bar(x + width/2, loss, width, label='Loss', color='red')\n",
        "\n",
        "# Labels and formatting\n",
        "ax.set_ylabel('Value')\n",
        "ax.set_title('Clean vs Adversarial Evaluation')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "ax.set_ylim(0, 1.1)\n",
        "\n",
        "# Annotate bars\n",
        "for bars in [bar1, bar2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{height:.2f}',\n",
        "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                    xytext=(0, 5),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "# Show\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Sey9UhMl6a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = iter(imagenette_val)\n",
        "images, labels = next(dl)\n",
        "\n",
        "output_path = \"/content/grid.png\"\n",
        "save_image(images.unsqueeze(0), output_path)"
      ],
      "metadata": {
        "id": "rx88WLYp4MJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import make_grid, save_image\n",
        "import os\n",
        "\n",
        "# Get the first batch\n",
        "dataiter = iter(imagenette_val)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Create a grid from the batch\n",
        "grid = make_grid(images, nrow=8, normalize=True, padding=2)\n",
        "\n",
        "# Save the grid to a file\n",
        "output_path = \"/content/grid.png\"\n",
        "save_image(grid, output_path)\n",
        "\n",
        "print(f\"Saved grid image to {output_path}\")"
      ],
      "metadata": {
        "id": "7wZBjyOc6HDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('model (1).pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "\n",
        "model.eval()  # Important if you're doing inference"
      ],
      "metadata": {
        "id": "GBQP5owI7UjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import make_grid, save_image\n",
        "import os\n",
        "\n",
        "# Get the first batch\n",
        "dataiter = iter(imagenette_val)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "images = images.to('cuda')\n",
        "labels = labels.to('cuda')\n",
        "model = model.to('cuda')\n",
        "\n",
        "attacked_batch = adversarial_attack(model, images, labels, lambda_reg=0.05, epsilon=0.01)\n",
        "\n",
        "# Create a grid from the batch\n",
        "grid = make_grid(attacked_batch, nrow=8, normalize=True, padding=2)\n",
        "\n",
        "# Save the grid to a file\n",
        "output_path = \"/content/grid_attack.png\"\n",
        "save_image(grid, output_path)\n",
        "\n",
        "print(f\"Saved grid image to {output_path}\")"
      ],
      "metadata": {
        "id": "CvX_afZ-6lgT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}